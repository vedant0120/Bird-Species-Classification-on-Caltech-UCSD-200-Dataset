{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXfI7z2OWBu8"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "W3DnbeInVyzJ"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Flatten, Reshape\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.pooling import GlobalMaxPooling2D\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QI8g0ow75XGU"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6ljFwsiPSGSe"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def prepare():                                                                    \n",
    "    imgdata=[]                                                                                  # Declaring Empty arrays\n",
    "    classdata=[]                                                                                # Declaring Empty arrays \n",
    "    labels=np.loadtxt(\"/content/drive/My Drive/CUB_200_2011/image_class_labels.txt\",dtype=str)  # Load labels file \n",
    "    labels=labels[:,1]\n",
    "    image_path=np.loadtxt(\"/content/drive/My Drive/CUB_200_2011/classes.txt\",dtype=str)          # Load Classes data file\n",
    "    image_path=image_path[:,1]\n",
    "    birds=np.loadtxt(\"/content/drive/My Drive/CUB_200_2011/images.txt\",dtype=str)                # Load images data file\n",
    "    birds=birds[:,1]\n",
    "    print(birds[0])\n",
    "    for images in birds:\n",
    "        filename=\"/content/drive/My Drive/CUB_200_2011/images/\"+str(images)                      # Append names of the images \n",
    "        img=image.load_img(filename,target_size=(200,200))                                       # Loading the image\n",
    "        x1=image.img_to_array(img)                                                               # Convert Image instance to a Numpy array.\n",
    "        print(filename)\n",
    "        imgdata.append(x1)                                                                       # Append each entry in an array\n",
    "    image_data=np.array(imgdata)                                                                 # Convert it to numpy array \n",
    "    print(image_data.shape)\n",
    "    print(labels.shape)\n",
    "    np.save('image_data.npy',image_data)                                                         # Store image_data to a file\n",
    "    \n",
    "\n",
    "prepare()                                                                                        # Calling the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xc5CBDAryzzr"
   },
   "source": [
    "# Loading and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dFLSaCuWfk6H"
   },
   "outputs": [],
   "source": [
    "labels=np.loadtxt(\"/content/drive/My Drive/CUB_200_2011/image_class_labels.txt\",dtype=int)            # Loading the class_labels\n",
    "labels=labels[:,1]\n",
    "labels=labels-1\n",
    "imagedata=np.load('image_data.npy')                                                                   # Loading the prepared data\n",
    "labeldata=keras.utils.to_categorical(labels,200)                                                      # Converting into Categorical Data\n",
    "print(labeldata.shape)\n",
    "X_train,X_test,y_train,y_test=train_test_split(imagedata,labeldata,test_size=1/6,stratify=labeldata)  # Train-Test Split\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j-gbpT-cy_2z"
   },
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "meJiodXCfpAs"
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                                            # Creating a sequential model\n",
    "model.add(Conv2D(input_shape=(200,200,3), filters=96, kernel_size=(3,3)))       # Input layer as 2D convolution layer with filters = 96\n",
    "model.add(Activation('relu'))                                                   # Apply Relu Activation Function                                               \n",
    "model.add(Conv2D(filters=96, kernel_size=(3,3), strides=2))                     # Apply 2D convolution hidden layer with filters = 96\n",
    "model.add(Activation('relu'))                                                   # Apply Relu Activation Function \n",
    "model.add(Dropout(0.2))                                                         # Apply Dropout to the input\n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3)))                               # Apply 2D convolution hidden layer with filters = 192\n",
    "model.add(Activation('relu'))                                                   # Apply Relu Activation Function   \n",
    "model.add(Conv2D(filters=192, kernel_size=(3,3), strides=2))                    # Apply 2D convolution hidden layer with filters = 192\n",
    "model.add(Activation('relu'))                                                   # Apply Relu Activation Function \n",
    "model.add(Dropout(0.5))                                                         # Apply Dropout to the input\n",
    "model.add(Flatten())                                                            # Flattening the input\n",
    "model.add(BatchNormalization())                                                 # Normalizing the  data\n",
    "model.add(Dense(256))                                                           # Dense thus is used to change the dimensions of vectors\n",
    "model.add(Activation('relu'))                                                   # Applying Relu Activation Function\n",
    "model.add(Dense(200, activation=\"softmax\"))                                     # Apply Softmax Activation Function on the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RhAWQiryza0P"
   },
   "source": [
    "# Evaluating Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "-1-1ZuJgge5I"
   },
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(lr=0.001, momentum=0.99, decay=1e-5, nesterov=True)  # Stochastic Gradient Descent Optimmizer\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,                       # Cross_entropy as Loss Function\n",
    "      optimizer=sgd,\n",
    "      metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,                                           # Model Fitting\n",
    "      batch_size=128,                                                           # Batch-size = 128\n",
    "      epochs=30,                                                                # Epochs = 30\n",
    "      verbose=1)\n",
    "score=model.evaluate(X_test,y_test,verbose=0)                                   # Evaluating Model\n",
    "print('Test accuracy:',score[1])                                                # Printing the accuracy"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DL_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
